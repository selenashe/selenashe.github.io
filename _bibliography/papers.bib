---
---

@article {Kauf2024.06.21.599332,
	author = {Kauf, Carina and Kim, Hee So and Lee, Elizabeth J. and Jhingan, Niharika and She, Jingyuan Selena and Taliaferro, Maya and Gibson, Edward and Fedorenko, Evelina},
	title = {Linguistic inputs must be syntactically parsable to fully engage the language network},
	elocation-id = {2024.06.21.599332},
	year = {2024},
	doi = {10.1101/2024.06.21.599332},
	publisher = {Cold Spring Harbor Laboratory},
	abstract = {Human language comprehension is remarkably robust to ill-formed inputs (e.g., word transpositions). This robustness has led some to argue that syntactic parsing is largely an illusion, and that incremental comprehension is more heuristic, shallow, and semantics-based than is often assumed. However, the available data are also consistent with the possibility that humans always perform rule-like symbolic parsing and simply deploy error correction mechanisms to reconstruct ill-formed inputs when needed. We put these hypotheses to a new stringent test by examining brain responses to a) stimuli that should pose a challenge for syntactic reconstruction but allow for complex meanings to be built within local contexts through associative/shallow processing (sentences presented in a backward word order), and b) grammatically well-formed but semantically implausible sentences that should impede semantics-based heuristic processing. Using a novel behavioral syntactic reconstruction paradigm, we demonstrate that backward- presented sentences indeed impede the recovery of grammatical structure during incremental comprehension. Critically, these backward-presented stimuli elicit a relatively low response in the language areas, as measured with fMRI. In contrast, semantically implausible but grammatically well-formed sentences elicit a response in the language areas similar in magnitude to naturalistic (plausible) sentences. In other words, the ability to build syntactic structures during incremental language processing is both necessary and sufficient to fully engage the language network. Taken together, these results provide strongest to date support for a generalized reliance of human language comprehension on syntactic parsing.Significance statement Whether language comprehension relies predominantly on structural (syntactic) cues or meaning- related (semantic) cues remains debated. We shed new light on this question by examining the language brain areas{\textquoteright} responses to stimuli where syntactic and semantic cues are pitted against each other, using fMRI. We find that the language areas respond weakly to stimuli that allow for local semantic composition but cannot be parsed syntactically{\textemdash}as confirmed in a novel behavioral paradigm{\textemdash}and they respond strongly to grammatical but semantically implausible sentences, like the famous {\textquoteleft}Colorless green ideas sleep furiously{\textquoteright} sentence. These findings challenge accounts of language processing that suggest that syntactic parsing can be foregone in favor of shallow semantic processing.Competing Interest StatementThe authors have declared no competing interest.},
	URL = {https://www.biorxiv.org/content/early/2024/06/22/2024.06.21.599332},
	eprint = {https://www.biorxiv.org/content/early/2024/06/22/2024.06.21.599332.full.pdf},
	journal = {bioRxiv}
}

@inproceedings{she-etal-2023-scone,
    title = "{S}co{N}e: Benchmarking Negation Reasoning in Language Models With Fine-Tuning and In-Context Learning",
    author = "She, Jingyuan Selena  and
      Potts, Christopher  and
      Bowman, Samuel R.  and
      Geiger, Atticus",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-short.154",
    doi = "10.18653/v1/2023.acl-short.154",
    pages = "1803--1821",
    abstract = "A number of recent benchmarks seek to assess how well models handle natural language negation. However, these benchmarks lack the controlled example paradigms that would allow us to infer whether a model had truly learned how negation morphemes semantically scope. To fill these analytical gaps, we present the Scoped Negation NLI (ScoNe-NLI) benchmark, which contains contrast sets of six examples with up to two negations where either zero, one, or both negative morphemes affect the NLI label. We use ScoNe-NLI to assess fine-tuning and in-context learning strategies. We find that RoBERTa and DeBERTa models solve ScoNe-NLI after many shot fine-tuning. For in-context learning, we test the latest InstructGPT models and find that most prompt strategies are not successful, including those using step-by-step reasoning. To better understand this result, we extend ScoNe with ScoNe-NLG, a sentence completion test set that embeds negation reasoning in short narratives. Here, InstructGPT is successful, which reveals the model can correctly reason about negation, but struggles to do so on NLI examples outside of its core pretraining regime.",
}

@inproceedings{zhang2023you,
  title={You are what you’re for: Essentialist categorization in large language models},
  author={Zhang*, Siying and She*, Jingyuan Selena and Gerstenberg, Tobias and Rose, David},
  booktitle={Proceedings of the Annual Meeting of the Cognitive Science Society},
  volume={45},
  year={2023},
  url={https://escholarship.org/uc/item/3996v30z}
}

@inproceedings{she2023language,
  title={Language Models Show Within- and Cross-language Similarities in Concrete Noun Meaning, but not Differences Between L1 and L2 English Speakers},
  author={She, Jingyuan Selena and Ma, Gabrielle and Wen, Ping and Zinszer, Benjamin D.},
  booktitle={Proceedings of the Annual Meeting of the Cognitive Science Society},
  volume={45},
  year={2023},
  url={https://escholarship.org/uc/item/4748z6vz}
}

@article{https://doi.org/10.1111/cogs.13386,
author = {Kauf, Carina and Ivanova, Anna A. and Rambelli, Giulia and Chersoni, Emmanuele and She, Jingyuan Selena and Chowdhury, Zawad and Fedorenko, Evelina and Lenci, Alessandro},
title = {Event Knowledge in Large Language Models: The Gap Between the Impossible and the Unlikely},
journal = {Cognitive Science},
volume = {47},
number = {11},
pages = {e13386},
keywords = {Generalized event knowledge, World knowledge, Plausibility, Typicality, Artificial neural networks, Language models, Syntax, Semantics},
doi = {https://doi.org/10.1111/cogs.13386},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cogs.13386},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/cogs.13386},
abstract = {Abstract Word co-occurrence patterns in language corpora contain a surprising amount of conceptual knowledge. Large language models (LLMs), trained to predict words in context, leverage these patterns to achieve impressive performance on diverse semantic tasks requiring world knowledge. An important but understudied question about LLMs’ semantic abilities is whether they acquire generalized knowledge of common events. Here, we test whether five pretrained LLMs (from 2018's BERT to 2023's MPT) assign a higher likelihood to plausible descriptions of agent−patient interactions than to minimally different implausible versions of the same event. Using three curated sets of minimal sentence pairs (total n = 1215), we found that pretrained LLMs possess substantial event knowledge, outperforming other distributional language models. In particular, they almost always assign a higher likelihood to possible versus impossible events (The teacher bought the laptop vs. The laptop bought the teacher). However, LLMs show less consistent preferences for likely versus unlikely events (The nanny tutored the boy vs. The boy tutored the nanny). In follow-up analyses, we show that (i) LLM scores are driven by both plausibility and surface-level sentence features, (ii) LLM scores generalize well across syntactic variants (active vs. passive constructions) but less well across semantic variants (synonymous sentences), (iii) some LLM errors mirror human judgment ambiguity, and (iv) sentence plausibility serves as an organizing dimension in internal LLM representations. Overall, our results show that important aspects of event knowledge naturally emerge from distributional linguistic patterns, but also highlight a gap between representations of possible/impossible and likely/unlikely events.},
year = {2023}
}


